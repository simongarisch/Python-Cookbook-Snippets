{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12 - Concurrency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting and Stopping Threads\n",
    "The threading library can be used to execute any Python callable in its own thread. To do this, you create a Thread instance and supply the callable that you wish to execute as a target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def countdown(n):\n",
    "    while n > 0:\n",
    "        print('T-minus', n)\n",
    "        n -= 1\n",
    "        time.sleep(0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-minus 5\n",
      "T-minus 4\n",
      "T-minus 3\n",
      "T-minus 2\n",
      "T-minus 1\n"
     ]
    }
   ],
   "source": [
    "from threading import Thread\n",
    "\n",
    "t = Thread(target=countdown, args=(5,))\n",
    "t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.is_alive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interpreter remains running until all threads terminate. For long-running threads or background tasks that run forever, you should consider making the thread daemonic. Daemon threads are destroyed when the main thread terminates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-minus 5\n",
      "T-minus 4\n",
      "T-minus 3\n",
      "T-minus 2\n",
      "T-minus 1\n"
     ]
    }
   ],
   "source": [
    "t = Thread(target=countdown, args=(5,), daemon=True)\n",
    "t.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to be able to terminate threads, the thread must be programmed to poll for exit at selected points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CountdownTask:\n",
    "    def __init__(self):\n",
    "        self._running = True\n",
    " \n",
    "    def terminate(self):\n",
    "        self._running = False\n",
    "\n",
    "    def run(self, n):\n",
    "        while self._running and n > 0:\n",
    "            print('T-minus', n)\n",
    "            n -= 1\n",
    "            time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-minus 10\n",
      "T-minus 9\n"
     ]
    }
   ],
   "source": [
    "c = CountdownTask()\n",
    "t = Thread(target=c.run, args=(10,))\n",
    "t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.terminate() # signal termination\n",
    "t.join()      # wait for actual termination (if needed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polling for thread termination can be tricky to coordinate if threads perform blocking operations such as I/O. To correctly deal with this case, you’ll need to carefully program thread to utilize timeout loops. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IOTask:\n",
    "    def terminate(self):\n",
    "        self._running = False\n",
    " \n",
    "    def run(self, sock):\n",
    "        # sock is a socket\n",
    "        sock.settimeout(5)  # set timeout period\n",
    "        while self._running:\n",
    "            # perform a blocking I/O operation w/ timeout\n",
    "            try:\n",
    "                data = sock.recv(8192)\n",
    "                break\n",
    "            except socket.timeout:\n",
    "                continue\n",
    "                # continued processing\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to a global interpreter lock (GIL), Python threads are restricted to an execution model that only allows one thread to execute in the interpreter at any given time. For this reason, Python threads should generally not be used for computationally intensive tasks where you are trying to achieve parallelism on multiple CPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes you will see threads defined via inheritance from the Thread class. Although this works, it introduces an extra dependency between the code and the threading library. By freeing your code of such dependencies, it becomes usable in other\n",
    "contexts that may or may not involve threads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining If a Thread Has Started\n",
    "To solve such problems, use the Event object from the threading library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching countdown\n",
      "countdown starting\n",
      "T-minus 5\n",
      "countdown is running\n",
      "T-minus 4\n",
      "T-minus 3\n",
      "T-minus 2\n",
      "T-minus 1\n"
     ]
    }
   ],
   "source": [
    "from threading import Thread, Event\n",
    "import time\n",
    "\n",
    "\n",
    "def countdown(n, started_evt):\n",
    "    print('countdown starting')\n",
    "    started_evt.set()\n",
    "    while n > 0:\n",
    "        print('T-minus', n)\n",
    "        n -= 1\n",
    "        time.sleep(1)\n",
    "\n",
    "\n",
    "started_evt = Event()\n",
    "print('Launching countdown')\n",
    "t = Thread(target=countdown, args=(5, started_evt))\n",
    "t.start()\n",
    "\n",
    "# wait for the thread to start\n",
    "started_evt.wait()\n",
    "print('countdown is running')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a thread is going to repeatedly signal an event over and over, you’re probably better off using a [Condition](https://docs.python.org/3/library/threading.html#condition-objects) object instead. For example, this code implements a periodic timer that other threads can monitor to see whenever the timer expires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "\n",
    "class PeriodicTimer:\n",
    "    def __init__(self, interval):\n",
    "        self._interval = interval\n",
    "        self._flag = 0\n",
    "        self._cv = threading.Condition()\n",
    " \n",
    "    def start(self):\n",
    "        t = threading.Thread(target=self.run)\n",
    "        t.daemon = True\n",
    "        t.start()\n",
    "\n",
    "    def run(self):\n",
    "        '''\n",
    "        Run the timer and notify waiting threads after each interval\n",
    "        '''\n",
    "        while True:\n",
    "            time.sleep(self._interval)\n",
    "            with self._cv:\n",
    "                self._flag ^= 1\n",
    "                self._cv.notify_all()\n",
    "\n",
    "    def wait_for_tick(self):\n",
    "        '''\n",
    "        Wait for the next tick of the timer\n",
    "        '''\n",
    "        with self._cv:\n",
    "            last_flag = self._flag\n",
    "            while last_flag == self._flag:\n",
    "                self._cv.wait()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example use of the timer\n",
    "ptimer = PeriodicTimer(2)\n",
    "ptimer.start()\n",
    "\n",
    "# two threads that synchronize on the timer\n",
    "def countdown(nticks):\n",
    "    while nticks > 0:\n",
    "        ptimer.wait_for_tick()\n",
    "        print('T-minus', nticks)\n",
    "        nticks -= 1\n",
    "\n",
    "def countup(last):\n",
    "    n = 0\n",
    "    while n < last:\n",
    "        ptimer.wait_for_tick()\n",
    "        print('Counting', n)\n",
    "        n += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-minus 10\n",
      "Counting 0\n",
      "T-minusCounting 1\n",
      " 9\n",
      "CountingT-minus 8\n",
      " 2\n",
      "CountingT-minus 7 3\n",
      "\n",
      "CountingT-minus 6\n",
      " 4\n",
      "T-minus 5\n",
      "T-minus 4\n",
      "T-minus 3\n",
      "T-minus 2\n",
      "T-minus 1\n"
     ]
    }
   ],
   "source": [
    "threading.Thread(target=countdown, args=(10,)).start()\n",
    "threading.Thread(target=countup, args=(5,)).start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Communicating Between Threads\n",
    "Perhaps the safest way to send data from one thread to another is to use a Queue from the queue library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "from queue import Queue\n",
    "from threading import Thread\n",
    "\n",
    "# a thread that produces data\n",
    "def producer(out_q):\n",
    "    data = 1\n",
    "    while True:\n",
    "        out_q.put(data)\n",
    "        data += 1\n",
    "        if data > 5:\n",
    "            break\n",
    "\n",
    "# a thread that consumes data\n",
    "def consumer(in_q):\n",
    "    while True:\n",
    "        data = in_q.get()\n",
    "        print(data)\n",
    "\n",
    "\n",
    "# create the shared queue and launch both threads\n",
    "q = Queue()\n",
    "t1 = Thread(target=consumer, args=(q,))\n",
    "t2 = Thread(target=producer, args=(q,))\n",
    "t1.start()\n",
    "t2.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queue instances already have all of the required locking, so they can be safely shared by as many threads as you wish."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using queues, it can be somewhat tricky to coordinate the shutdown of the producer and consumer. A common solution to this problem is to rely on a special sentinel value, which when placed in the queue, causes consumers to terminate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "from queue import Queue\n",
    "from threading import Thread\n",
    "\n",
    "_sentinel = object()\n",
    "\n",
    "# a thread that produces data\n",
    "def producer(out_q):\n",
    "    data = 1\n",
    "    while True:\n",
    "        out_q.put(data)\n",
    "        data += 1\n",
    "        if data > 5:\n",
    "            out_q.put(_sentinel)\n",
    "\n",
    "# a thread that consumes data\n",
    "def consumer(in_q):\n",
    "    while True:\n",
    "        data = in_q.get()\n",
    "        \n",
    "        if data is _sentinel:\n",
    "            in_q.put(_sentinel)\n",
    "            break\n",
    "\n",
    "        print(data)\n",
    "\n",
    "\n",
    "# create the shared queue and launch both threads\n",
    "q = Queue()\n",
    "t1 = Thread(target=consumer, args=(q,))\n",
    "t2 = Thread(target=producer, args=(q,))\n",
    "t1.start()\n",
    "t2.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A subtle feature of this example is that the consumer, upon receiving the special sentinel value, immediately places it back onto the queue. This propagates the sentinel to other consumers threads that might be listening on the same queue—thus shutting them all down one after the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a thread needs to know immediately when a consumer thread has processed a particular item of data, you should pair the sent data with an Event object that allows the producer to monitor its progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "from queue import Queue\n",
    "from threading import Thread, Event\n",
    "\n",
    "collection = list(range(1,6))\n",
    "\n",
    "def producer(out_q):\n",
    "    while True:\n",
    "        if len(collection) == 0:\n",
    "            break\n",
    "        data = collection.pop()\n",
    "        evt = Event()\n",
    "        out_q.put((data, evt))\n",
    "        evt.wait()\n",
    "\n",
    "\n",
    "def consumer(in_q):\n",
    "    while True:\n",
    "        data, evt = in_q.get()\n",
    "        print(data)\n",
    "        evt.set()\n",
    "\n",
    "\n",
    "q = Queue()\n",
    "t1 = Thread(target=consumer, args=(q,))\n",
    "t2 = Thread(target=producer, args=(q,))\n",
    "t1.start()\n",
    "t2.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are concerned about shared state, it may make sense to only pass immutable data structures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Locking Critical Sections\n",
    "Your program uses threads and you want to lock critical sections of code to avoid race conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "class SharedCounter:\n",
    "    def __init__(self, initial_value = 0):\n",
    "        self._value = initial_value\n",
    "        self._value_lock = threading.Lock()\n",
    " \n",
    "\n",
    "    def incr(self,delta=1):\n",
    "        with self._value_lock:\n",
    "            self._value += delta\n",
    " \n",
    "    def decr(self,delta=1):\n",
    "        with self._value_lock:\n",
    "            self._value -= delta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The with statement is more elegant and less prone to error—especially in situations where a programmer might forget to call the release() method or if a program happens to raise an exception while holding a lock."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locking with Deadlock Avoidance\n",
    "You’re writing a multithreaded program where threads need to acquire more than one lock at a time while avoiding deadlock.\n",
    "\n",
    "For instance, if a thread acquires the first lock, but then blocks trying to acquire the second lock, that thread can potentially block the progress of other threads and make the program freeze. We can enforce an ordering rule that only allows multiple locks to be acquired in ascending order.\n",
    "\n",
    "See [treading.local()](https://docs.python.org/3/library/threading.html#thread-local-data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_thread._local at 0x22229904410>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import threading\n",
    "\n",
    "_local = threading.local()\n",
    "_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "from contextlib import contextmanager\n",
    "\n",
    "# thread-local state to stored information on locks already acquired\n",
    "_local = threading.local()\n",
    "\n",
    "@contextmanager\n",
    "def acquire(*locks):\n",
    "    # sort locks by object identifier\n",
    "    locks = sorted(locks, key=lambda x: id(x))\n",
    " \n",
    "    # make sure lock order of previously acquired locks is not violated\n",
    "    acquired = getattr(_local,'acquired',[])\n",
    "    if acquired and max(id(lock) for lock in acquired) >= id(locks[0]):\n",
    "        raise RuntimeError('Lock Order Violation')\n",
    "    \n",
    "    # acquire all of the locks\n",
    "    acquired.extend(locks)\n",
    "    _local.acquired = acquired\n",
    "\n",
    "    try:\n",
    "        for lock in locks:\n",
    "            lock.acquire()\n",
    "        yield\n",
    "    finally:\n",
    "        # Release locks in reverse order of acquisition\n",
    "        for lock in reversed(locks):\n",
    "            lock.release()\n",
    "        del acquired[-len(locks):]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use this context manager, you simply allocate lock objects in the normal way, but use the acquire() function whenever you want to work with one or more locks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread-1\n",
      "Thread-1\n",
      "Thread-1\n",
      "Thread-2\n",
      "Thread-2\n",
      "Thread-2\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "x_lock = threading.Lock()\n",
    "y_lock = threading.Lock()\n",
    "\n",
    "def thread_1():\n",
    "    count = 0\n",
    "    while True:\n",
    "        count += 1\n",
    "        with acquire(x_lock, y_lock):\n",
    "            print('Thread-1')\n",
    "        if count >= 3:\n",
    "            break\n",
    "\n",
    "def thread_2():\n",
    "    count = 0\n",
    "    while True:\n",
    "        count += 1\n",
    "        with acquire(y_lock, x_lock):\n",
    "            print('Thread-2')\n",
    "        if count >= 3:\n",
    "            break\n",
    "\n",
    "t1 = threading.Thread(target=thread_1)\n",
    "t1.daemon = True\n",
    "t1.start()\n",
    "\n",
    "t2 = threading.Thread(target=thread_2)\n",
    "t2.daemon = True\n",
    "t2.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The issue of deadlock is a well-known problem with programs involving threads (as well as a common subject in textbooks on operating systems). As a rule of thumb, as long as you can ensure that threads can hold only one lock at a time, your program will be deadlock free. However, once multiple locks are being acquired at the same time, all bets are off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing Thread-Specific State\n",
    "To do this, create a thread-local storage object using threading.local(). Attributes stored and read on this object are only visible to the executing thread and no others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from socket import socket, AF_INET, SOCK_STREAM\n",
    "import threading\n",
    "\n",
    "class LazyConnection:\n",
    "    def __init__(self, address, family=AF_INET, type=SOCK_STREAM):\n",
    "        self.address = address\n",
    "        self.family = AF_INET\n",
    "        self.type = SOCK_STREAM\n",
    "        self.local = threading.local()\n",
    " \n",
    "    def __enter__(self):\n",
    "        if hasattr(self.local, 'sock'):\n",
    "            raise RuntimeError('Already connected')\n",
    "        self.local.sock = socket(self.family, self.type)\n",
    "        self.local.sock.connect(self.address)\n",
    "        return self.local.sock\n",
    " \n",
    "    def __exit__(self, exc_ty, exc_val, tb):\n",
    "        self.local.sock.close()\n",
    "        del self.local.sock\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 400 bytes\n",
      "Got 400 bytes\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "def test(conn):\n",
    "    with conn as s:\n",
    "        s.send(b'GET /index.html HTTP/1.0\\r\\n')\n",
    "        s.send(b'Host: www.python.org\\r\\n')\n",
    "        s.send(b'\\r\\n')\n",
    "        resp = b''.join(iter(partial(s.recv, 8192), b''))\n",
    "    print('Got {} bytes'.format(len(resp)))\n",
    "\n",
    "\n",
    "conn = LazyConnection(('www.python.org', 80))\n",
    "t1 = threading.Thread(target=test, args=(conn,))\n",
    "t2 = threading.Thread(target=test, args=(conn,))\n",
    "t1.start()\n",
    "t2.start()\n",
    "t1.join()\n",
    "t2.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Thread(Thread-14, stopped 15412)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.is_alive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Thread Pool\n",
    "The concurrent.futures library has a ThreadPoolExecutor class that can be used for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing our Task\n",
      "Executing our Task\n",
      "I: 499999500000\n",
      "Task Executed <Thread(ThreadPoolExecutor-12_1, started daemon 12084)>\n",
      "I: 499999500000\n",
      "Task Executed <Thread(ThreadPoolExecutor-12_0, started daemon 15032)>\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import threading\n",
    "import random\n",
    "\n",
    "\n",
    "def task():\n",
    "    print(\"Executing our Task\")\n",
    "    result = 0\n",
    "    i = 0\n",
    "    for i in range(int(1e6)):\n",
    "        result = result + i\n",
    "    print(\"I: {}\".format(result))\n",
    "    print(\"Task Executed {}\".format(threading.current_thread()))\n",
    "\n",
    "    \n",
    "executor = ThreadPoolExecutor(max_workers=3)\n",
    "task1 = executor.submit(task)\n",
    "task2 = executor.submit(task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or for use as a context manager:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ThreadPoolExecutor\n",
      "Processing 2\n",
      "Processing 3\n",
      "Processing 4\n",
      "All tasks complete\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def task(n):\n",
    "    print(\"Processing {}\".format(n))\n",
    "\n",
    "\n",
    "print(\"Starting ThreadPoolExecutor\")\n",
    "with ThreadPoolExecutor(max_workers=3) as executor:\n",
    "    executor.submit(task, (2))\n",
    "    executor.submit(task, (3))\n",
    "    executor.submit(task, (4))\n",
    "\n",
    "print(\"All tasks complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing Simple Parallel Programming\n",
    "The concurrent.futures library provides a ProcessPoolExecutor class that can be used to execute computationally intensive functions in a separately running instance of the Python interpreter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import os\n",
    "\n",
    "\n",
    "def task():\n",
    "    print(\"Executing our Task on Process {}\".format(os.getpid()))\n",
    "\n",
    "    \n",
    "executor = ProcessPoolExecutor(max_workers=3)\n",
    "task1 = executor.submit(task)\n",
    "task2 = executor.submit(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import os\n",
    "\n",
    "def task():\n",
    "    print(\"Executing our Task on Process: {}\".format(os.getpid()))\n",
    "\n",
    "\n",
    "with ProcessPoolExecutor(max_workers=3) as executor:\n",
    "    task1 = executor.submit(task)\n",
    "    task2 = executor.submit(task)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Dealing with the GIL (and How to Stop Worrying About It)\n",
    "\n",
    "Although Python fully supports thread programming, parts of the C implementation of the interpreter are not entirely thread safe to a level of allowing fully concurrent execution. In fact, the interpreter is protected by a so-called Global Interpreter Lock\n",
    "(GIL) that only allows one Python thread to execute at any given time. It is important to emphasize that the GIL tends to only affect programs that are heavily CPU bound (i.e., dominated by computation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining an Actor Task\n",
    "The 'actor model' is one of the oldest and most simple approaches to concurrency and distributed computing. In fact, its underlying simplicity is part of its appeal. In a nutshell, an actor is a concurrently executing task that simply acts upon messages sent to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import Queue\n",
    "from threading import Thread, Event\n",
    "\n",
    "# Sentinel used for shutdown\n",
    "class ActorExit(Exception):\n",
    "    pass\n",
    "\n",
    "class Actor:\n",
    "    def __init__(self):\n",
    "        self._mailbox = Queue()\n",
    " \n",
    "    def send(self, msg):\n",
    "        self._mailbox.put(msg)\n",
    " \n",
    "    def recv(self):\n",
    "        msg = self._mailbox.get()\n",
    "        if msg is ActorExit:\n",
    "            raise ActorExit()\n",
    "        return msg\n",
    " \n",
    "    def close(self):\n",
    "        self.send(ActorExit)\n",
    " \n",
    "    def start(self):\n",
    "        self._terminated = Event()\n",
    "        t = Thread(target=self._bootstrap)\n",
    "        t.daemon = True\n",
    "        t.start()\n",
    "\n",
    "    def _bootstrap(self):\n",
    "        try:\n",
    "            self.run()\n",
    "        except ActorExit:\n",
    "            pass\n",
    "        finally:\n",
    "            self._terminated.set()\n",
    "    \n",
    "    def join(self):\n",
    "        self._terminated.wait()\n",
    "     \n",
    "    def run(self):\n",
    "        while True:\n",
    "            msg = self.recv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample ActorTask\n",
    "class PrintActor(Actor):\n",
    "    def run(self):\n",
    "        while True:\n",
    "            msg = self.recv()\n",
    "            print('Got:', msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got: Hello\n",
      "Got: World\n"
     ]
    }
   ],
   "source": [
    "p = PrintActor()\n",
    "p.start()\n",
    "p.send('Hello')\n",
    "p.send('World')\n",
    "p.close()\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Publish/Subscribe Messaging\n",
    "To implement publish/subscribe messaging, you typically introduce a separate 'exchange' or 'gateway' object that acts as an intermediary for all messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class Exchange:\n",
    "    def __init__(self):\n",
    "        self._subscribers = set()\n",
    "\n",
    "    def attach(self, task):\n",
    "        self._subscribers.add(task)\n",
    " \n",
    "    def detach(self, task):\n",
    "        self._subscribers.remove(task)\n",
    " \n",
    "    def send(self, msg):\n",
    "        for subscriber in self._subscribers:\n",
    "            subscriber.send(msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of all created exchanges\n",
    "_exchanges = defaultdict(Exchange)\n",
    "\n",
    "# return the exchange instance associated with a given name\n",
    "def get_exchange(name):\n",
    "    return _exchanges[name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Task:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def send(self, msg):\n",
    "        print(self.name, \"received\", msg)\n",
    "\n",
    "task_a = Task(\"task_a\")\n",
    "task_b = Task(\"task_b\")\n",
    "\n",
    "exc = get_exchange('name')\n",
    "exc.attach(task_a)\n",
    "exc.attach(task_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task_a received msg1\n",
      "task_b received msg1\n"
     ]
    }
   ],
   "source": [
    "exc.send('msg1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task_a received msg2\n",
      "task_b received msg2\n"
     ]
    }
   ],
   "source": [
    "exc.send('msg2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of unsubscribing\n",
    "exc.detach(task_a)\n",
    "exc.detach(task_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The concept of tasks or threads sending messages to one another (often via queues) is easy to implement and quite popular. However, the benefits of using a public/subscribe (pub/sub) model instead are often overlooked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a simple diagnostic class that would display sent messages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DisplayMessages:\n",
    "    def __init__(self):\n",
    "        self.count = 0\n",
    " \n",
    "    def send(self, msg):\n",
    "        self.count += 1\n",
    "        print('msg[{}]: {!r}'.format(self.count, msg))\n",
    "\n",
    "exc = get_exchange('name')\n",
    "d = DisplayMessages()\n",
    "exc.attach(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msg[1]: 'some'\n"
     ]
    }
   ],
   "source": [
    "exc.send(\"some\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msg[2]: 'data'\n"
     ]
    }
   ],
   "source": [
    "exc.send(\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Generators As an Alternative to Threads\n",
    "You want to implement concurrency using generators (coroutines) as an alternative to system threads. This is sometimes known as user-level threading or green threading.\n",
    "\n",
    "The fundamental behavior of yield is that it causes a generator to suspend its execution. By suspending execution, it is possible to write a scheduler that treats generators as a kind of 'task' and alternates their execution using a kind of cooperative task switching. Also see [deque](https://docs.python.org/2/library/collections.html#collections.deque)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countdown(n):\n",
    "    while n > 0:\n",
    "        print('T-minus', n)\n",
    "        yield\n",
    "        n -= 1\n",
    "    print('Blastoff!')\n",
    "\n",
    "\n",
    "def countup(n):\n",
    "    x = 0\n",
    "    while x < n:\n",
    "        print('Counting up', x)\n",
    "        yield\n",
    "        x += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class TaskScheduler:\n",
    "    def __init__(self):\n",
    "        self._task_queue = deque()\n",
    " \n",
    "    def new_task(self, task):\n",
    "        self._task_queue.append(task)\n",
    " \n",
    "    def run(self):\n",
    "        while self._task_queue:\n",
    "            task = self._task_queue.popleft()\n",
    "            try:\n",
    "                # run until the next yield statement\n",
    "                next(task)\n",
    "                self._task_queue.append(task)\n",
    "            except StopIteration:\n",
    "                pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-minus 10\n",
      "T-minus 5\n",
      "Counting up 0\n",
      "T-minus 9\n",
      "T-minus 4\n",
      "Counting up 1\n",
      "T-minus 8\n",
      "T-minus 3\n",
      "Counting up 2\n",
      "T-minus 7\n",
      "T-minus 2\n",
      "Counting up 3\n",
      "T-minus 6\n",
      "T-minus 1\n",
      "Counting up 4\n",
      "T-minus 5\n",
      "Blastoff!\n",
      "Counting up 5\n",
      "T-minus 4\n",
      "Counting up 6\n",
      "T-minus 3\n",
      "Counting up 7\n",
      "T-minus 2\n",
      "Counting up 8\n",
      "T-minus 1\n",
      "Counting up 9\n",
      "Blastoff!\n",
      "Counting up 10\n",
      "Counting up 11\n",
      "Counting up 12\n",
      "Counting up 13\n",
      "Counting up 14\n"
     ]
    }
   ],
   "source": [
    "sched = TaskScheduler()\n",
    "sched.new_task(countdown(10))\n",
    "sched.new_task(countdown(5))\n",
    "sched.new_task(countup(15))\n",
    "sched.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sched._task_queue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generator functions are the tasks and the yield statement is how tasks signal that they want to suspend. The scheduler simply cycles over the tasks until none are left executing. For a tread free version of actors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class ActorScheduler:\n",
    "    def __init__(self):\n",
    "        self._actors = {}  # mapping of names to actors\n",
    "        self._msg_queue = deque() # message queue\n",
    " \n",
    "    def new_actor(self, name, actor):\n",
    "        self._msg_queue.append((actor,None))\n",
    "        self._actors[name] = actor\n",
    " \n",
    "    def send(self, name, msg):\n",
    "        actor = self._actors.get(name)\n",
    "        if actor:\n",
    "            self._msg_queue.append((actor,msg))\n",
    " \n",
    "    def run(self):\n",
    "        while self._msg_queue:\n",
    "            actor, msg = self._msg_queue.popleft()\n",
    "            try:\n",
    "                actor.send(msg)\n",
    "            except StopIteration:\n",
    "                pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got: 7\n",
      "Got: 6\n",
      "Got: 5\n",
      "Got: 4\n",
      "Got: 3\n",
      "Got: 2\n",
      "Got: 1\n"
     ]
    }
   ],
   "source": [
    "def printer():\n",
    "    while True:\n",
    "        msg = yield\n",
    "        print('Got:', msg)\n",
    "\n",
    "def counter(sched):\n",
    "    while True:\n",
    "        n = yield\n",
    "        if n == 0:\n",
    "            break\n",
    "\n",
    "        sched.send('printer', n)\n",
    "        # Send the next count to the counter task (recursive)\n",
    "        sched.send('counter', n-1)\n",
    "    \n",
    "    \n",
    "sched = ActorScheduler()\n",
    "\n",
    "# Create the initial actors\n",
    "sched.new_actor('printer', printer())\n",
    "sched.new_actor('counter', counter(sched))\n",
    "\n",
    "# Send an initial message to the counter to initiate\n",
    "sched.send('counter', 7)\n",
    "sched.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polling Multiple Thread Queues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
